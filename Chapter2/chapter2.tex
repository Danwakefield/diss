%\addcontentsline{toc}{chapter}{Development Process}
\chapter{Design}

%You should concentrate on the more important aspects of the design. It is essential that an overview is presented before going into detail. As well as describing the design adopted it must also explain what other designs were considered and why they were rejected.

%The design should describe what you expected to do, and might also explain areas that you had to revise after some investigation.

%Typically, for an object-oriented design, the discussion will focus on the choice of objects and classes and the allocation of methods to classes. The use made of reusable components should be described and their source referenced. Particularly important decisions concerning data structures usually affect the architecture of a system and so should be described here.

%How much material you include on detailed design and implementation will depend very much on the nature of the project. It should not be padded out. Think about the significant aspects of your system. For example, describe the design of the user interface if it is a critical aspect of your system, or provide detail about methods and data structures that are not trivial. Do not spend time on long lists of trivial items and repetitive descriptions. If in doubt about what is appropriate, speak to your supervisor.
 
%You should also identify any support tools that you used. You should discuss your choice of implementation tools - programming language, compilers, database management system, program development environment, etc.

%Some example sub-sections may be as follows, but the specific sections are for you to define. 

\section{Language Choice}
As previously stated the language I chose for this project was Go.
This section aims to show why It was chosen over the other candidates I considered.

\subsection{Go}
Go, also known as Golang, is a statically typed, compiled, concurrent and garbage collected language heavily inspired by C for the general syntax, Limbo for it's use of Communicating Sequential Processes (CSP)\cite{HOARE-CSP} and Python for its emphasis on readability and an all inclusive standard library.
It is relatively modern, only released to the public in 2009, and was created to solve some of the problems experienced with the languages used at Google, namely C\verb!++!, Python and Java.
I began to learn it, through the Golang Challenge\cite{GOLANG-CHALLENGE},  during my industrial year after experiencing some of these problems with python myself.

The creators of the language are all well respected in the world of computing.
Rob Pike is known for Plan 9 and UTF8. 
Robert Griesemer for the Java hotspot VM
Ken Thompson for Unix, Plan 9 and B, the predecessor to C.
Their combined hatred of the complexity and compile times of C\verb!++! where the catalyst for Go's development.
They also saw it as an opportunity to improve upon the aspects of C that have been most problematic over the years including\cite{GO-DESIGN-EMAIL}.

\begin{itemize*}
	\item Optional braces around if statements (The cause of apples GOTO fail bug\cite{GOTOFAIL}).
	\item Pointer arithmetic.
    \item Unchecked array boundaries.
	\item Confusing side effects of post/pre increment and decrement. Go only allows the post version and only as a standalone expression.
	\item GOTO statements that can jump anywhere at any time.
    \item Overloaded return values used to indicate errors.
\end{itemize*}

The language also avoided style wars as it came with a tool, gofmt, that formats code 'the right way'.
This is just one of the ways in which Go is extremely opinionated.
Others include:
\begin{itemize*}
	\item Unused imports and variables are a compile time error.
    \item Variables names should be generally be short. The longer they are in scope the longer and more descriptive the name should be.
    \item The use of interface composition over polymorphism, generics and inheritance.
    \item One loop construct, the for loop. Use with a break statement to create a while or until loop.
\end{itemize*}

It also comes with a simple built in testing framework that encourages tests right from the start and a documentation generator emphasising that.

XXX
It also doesn't hurt that Go has been found that to be a great language to build components traditionally done with C, including things as complicated as a kernel subsystem\cite{GONET}.

Concurrency after moores law, cores increasing faster than ghz.

While this is the language I decided to go with in the end I did consider others.
The candidate list included C, C\verb!++!, Python and OCaml.

\subsection{C}
C is a fast, low level, general purpose compiled language that is extremely powerful.
Unfortunately this power comes at a cost.
Historically the readability of C code is low which means that maintaining and extending code is hard.
This would not a huge problem if I was only creating the project for the dissertation but I hope to continue development after submission.

I considered it as a candidate as many shells have already been written using it proving it is a suitable choice.
This could be considered both an advantage, the abundance of prior art, and a disadvantage, less room to find innovative solutions.

While I have used some C in the past and have read the seminal book, K\&R C, I would not consider myself experienced in its use, especially with the more modern aspects like compiler directives and function annotations.
This could have led to problems around having to learn parts of such a complex language while developing a large project.
Even though I did not end up using this language I spent lots of time reading the source code for dash, bash and busybox which are all written in C, therefore using it  may have helped in my context switches. 

One thing I was worried about was the minimal standard library that C implementations provide.
I assumed that I would be required to spend valuable development time creating standard functions and data structures.
However during my research I discovered that libraries such as GLib and qLibc are commonly used and provide most, if not all, of the things I am used to in the StdLib of Python.

I was also worried about introducing the classes of bugs common in C programs such as use after free, memory leaks, buffer under and over flows and format string attacks,


Something to note is that I discovered a library, libmill\cite{LIBMILL}, which provides functions and macros for Go like CSP.



\subsection{C++}


As with anything based in C, C\verb!++! may be considered the obvious step forward.
I have never used the language but have read the source code for a few projects written using it.
It has a fairly complete standard library and some of the memory management is abstracted behind constructor's and destructor's.
Despite this it is notoriously difficult and If the project where to use it it may be tied to one architecture and OS unless a lot of extra effort was put in.

\subsection{OCaml}
OCaml is a functional, garbage collected, compiled language.
It is a multi paradigm language that allows users to mix object oriented, imperative and functional styles.

I considered it as a candidate as it is often said that ML languages are superior to imperative ones at creating compilers and interpretors. 
This is because construction and modification of tree structures, such as the abstract syntax tree required in interpretors, using pattern matching and algebraic data types is very idiomatic in these types of languages.

I chose to consider it over other functional languages as it had recently come to my attention when it was used to create the high profile language Hack at Facebook.
As well as this it has been used for the Haxe language, the MirageOS unikernel and many code analysis tools.
These are all complex systems that show that the performance and the bulitin parsing tools are up to tasks well above the complexity of a simple interpretor.

I however had no experience at all with OCaml and very little with ML languages in general.



\subsection{Python}



\section{High level design}
This section will describe the high level design of the shell and illustrate to a user with no knowledge of the internals of a shell how components interact with each other.

Figure~\ref{fig:shell-flowchart} is a visual guide to this though it should be noted that the flowchart is not totally representative of the system and is just here to show the progression of data.


\subsection{Input}
The first step we need to do is get the text that represents the shell program in some way.
This can come in from a pipe, be read from a file or entered into an interactive session.
Due to the time restrictions, gosh does not currently support interactive use though this something I plan to add in the near future.
This text is then used to construct a lexer, parser pair.

\subsection{Lexer}
The lexer operates on the raw text a rune\footnote{Go has the concept of a rune which is a type alias of an int32 used to hold a unicode character.} at a time.
These runes are turned into a stream of normalized tokens, removing comments and whitespace.
In some cases, when we are expecting some other terminating token such as the 'fi' following an 'if' block, newlines are also removed.
The lexer can also detect some errors that don't require deep knowledge of the language grammar such as unterminated strings and incomplete variable substitutions. 

However the POSIX spec is very lenient in most scenarios and many things that would be considered errors in other languages are ignored or resolved in some way.
An example of this is the variable symbol '\$', by itself or followed by a character that would be invalid in the first position of a variable name it becomes a literal character with no special meaning.

The lexer also handles alias expansion.
This means that the first word of any line should be checked against a list of expansions, if it matches the word is replaced by the expanded text and lexing begins again at the start of the line.

However as this example shows this can result in the common compiler construction problem known as left recursion.
\begin{verbatim}
$ alias foo=bar
$ alias bar=baz
$ alias baz=foo

$ foo
\end{verbatim}

Care must be taken to avoid this as it will cause an infinite loop breaking the lexer.
Gosh does not currently support aliases for this reason but structures have been put in place so adding support in the future will be possible.

XXX %Lexer generators, ANTLR (Doesnt support GO), Ragel (Does), Hard to do things like substiutions embedded in strings etc.

\subsection{Parser}
The next step is using the Parser to check the semantic meaning of these Tokens and to use them to create the nodes for an AST.
This is also the point where any remaining syntax errors should be detected.

There are many tools available to generate parsers and Go includes an implementation of yacc, one of the most famous, in its toolchain.
The Bash shell even uses bison to generate its parser.
However I feared that using one would have taught me more about the tool than parsers in general making debugging of the generated code more difficult 
Chet Ramey, the maintainer of bash has also stated if he was starting over he would write a recursive descent parser himself\cite{BASH-ARCH} instead of using a generator.

I chose to write a predictive recursive descent parser(RDP) for a few reasons.
\begin{enumerate*}
	\item It is a simple, logical design and is relatively easy to implement by hand.
    \item It works with the class of grammar that the shell language has (
    LL(1) explained further in XXX)
    \item dash and zsh both use RDP's giving some prior art to draw from as well as proving it is a suitable construct for the task.
\end{enumerate*}

There was also the option of an LALR or LR lookahead parsers and backtracking parsers.
The main reason I did not go with one of these was the lack of information available about them.


XXX % Write more.

\subsection{Nodes \& the AST}
The Abstract Syntax Tree (AST) returned from the parser can consist of any number of nodes each of which can contain further child trees.

Nodes in this tree satisfy an interface called Node, which contains a single method called Eval.
Each Node is a separate type that contains fields relevant to itself.
The types then satisfy this interface with code that knows how to perform the actions of that node and hand execution off to child nodes when appropriate.

As with any tree something has to be terminal.
There are three things that are considered terminal when returned from the parser and each is treated differently.

The NodeCommand is terminal since it returns an exit code, but it is also a valid AST.
This node handles execution of system utilities, builtins and user defined functions as well as the redirection of their input and output to the requested files, pipes or file descriptors.
This is known as a 'simple command' in the specification and is the building block for 'compound commands'.

The NodeEOF indicate that the input has been exhausted and the shell should return with the last exit code it received.
The main loop checks explicitly for it with a type check.
The layout of the parser means that nothing else can receive this as a valid node.

Finally there is 'nil' which is to be used as a signal to the interactive session.
It is also used in the NodeCaseList to indicate that the case contains no code.
XXX %This should be changed to a NOOPNode which NodeEOF can embed.

Go allowed me to express nodes in a clean way through the use of interfaces and structs.
This is a big change from how they are expressed in dash's C code.
There they consist of DEFINED constants, huge union structs and evaluation code in a single function with GOTO's and XXX

\subsection{Expansion}
While the diagram shows that only NodeCommands undergo expansion this is a slight lie to keep it simple.
The Arg structures contained in a NodeFor and a NodeCase are also expanded when required but they don't cause any command execution.

When evaluation hits a NodeCommand we know we are going to do either set some variables \verb!A=1 B=2! or run some sort of command, with optionally prepended assignments\verb!A=1 foo!.
In either case it is possible that a value exists that requires expansion e.g \verb!A="$X $(foo) $((3+4))" B=*.c!.

The expansion pipeline performs these expansions in order returning a list of strings as some of the expansions can result in multiple words.
These include:
\begin{description*}
	\item Tilde expansion \hfill \\
    	Turning the '\textasciitilde' character into the filepath of home or named directory's.
    	This expansion only occurs at certain positions in unquoted words.
    \item Subshell expansion \hfill \\
    	This expansion starts another evaluation loop with certain IO redirections so the output of the subshell can be placed as a string in its place.
	\item Arithmetic expansion \hfill \\
    	Arithmetic is sufficiently complicated that it requires a call to a separate lexer parser pair.
        This expansion calls the exposed Parse function and receives an integer in return which can be converted to a string.
    \item Variable Substitution \hfill \\
    	There are some complex variable replacements which can alter the contents, assign new values or even exit the shell with an error in some cases.
	\item Filepath globbing \hfill \\
    	Unquoted strings containing globbing meta characters are expanded to a list of files in the current directory that match the pattern.
        If no files match the pattern it is returned as a literal string.
\end{description*}

Bash and other modern shells extend these further to include brace expansion and process substitution.

\subsection{Execution}

XXX

\begin{figure}[hp]
    \centering
    \includegraphics[scale=0.7]{shell-design.png}
    \caption[Shell execution pipeline]{Shows how input is transformed along the way to being executed commands.}
    \label{fig:shell-flowchart}
\end{figure}

\section{Arithmetic}

This section is about the arithmetic construct, the reasons why it requires it's own lexer-parser and how this pair differs from the one used for the general shell language.



















\section{Other relevant sections}
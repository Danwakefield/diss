\chapter{Implementation}

%The implementation should look at any issues you encountered as you tried to implement your design. During the work, you might have found that elements of your design were unnecessary or overly complex; perhaps third party libraries were available that simplified some of the functions that you intended to implement. If things were easier in some areas, then how did you adapt your project to take account of your findings?

%It is more likely that things were more complex than you first thought. In particular, were there any problems or difficulties that you found during implementation that you had to address? Did such problems simply delay you or were they more significant? 

%You can conclude this section by reviewing the end of the implementation stage against the planned requirements. 

\section{Arithmetic}
The arithmetic construct was the first thing I created.
It is a standalone piece of code only exposing a single method, Parse, which takes a string representing an equation and returning the integer value it evaluates to or an error.
Because of this isolation I created it as a subpackage which also allowed me to simplify the error handling.

I was able to panic and recover\footnote{Panic is similar to an exception in other languages but has different semantics. Errors in Go should be passed through the use of multiple return values instead.} to completely unwind the parser and lexer.
Although panics are reserved for truly exceptional cases in Go, they had to be used in this case.
Errors encountered during lexing or parsing of a language are almost always fatal as they leave the system in an indeterminate state.
For example, the following make no sense in the context of a shell mathematical equation:
\begin{verbatim}
++
  or
35 67 89
\end{verbatim}
This is an implementation detail and can of course be treated differently.
In bash the '++' symbol can represent post-increment or pre-increment depending on its position.
The numbers could also be joined together into a single literal; Python and Java do something similar with underscores rather than spaces\cite{UNDERSCORE-NUM-LITERAL}.

Another of Go's golden rules is never to raise a panic across package boundaries and to do this we defer a recover function.
If recover detects we have panicked it checks to see if it should be returned as an error instead.
Unfortunately during testing I discovered that the checks where not through enough and allowed division by zero errors to bubble up crashing the whole program. 
The fix for this would be quite simple, it just requires the addition of a division helper function similar to that used for shifting (See \ref{lst:arith-shift}). XXX % Add reference to integration test that caught it.
\newpage %XXX NEWPAGE 
\subsection{Lexer}
The Lexer was completed during the first iteration as planned and has a good set of unit tests that where used to ensure the correctness of returned tokens.

The syntax for an equation is quite simple, consisting of just:
\begin{itemize*}
	\item Variable Names
    \item Symbols
	\item Numeric Literals
\end{itemize*}

Variable names are detected using the following simple regular expression, \verb![a-zA-Z_][a-zA-Z0-9_]*!.

POSIX requires that detection of numeric values can be done in base 8 (Octal), 10 (Decimal) and 16 (Hexadecimal).
Values are always converted to base 10 for use inside the lexer.
If the literal is invalid, e.g \verb!0xffk! an error is returned that unwinds the parser.
With the current design if assignments have been applied before the error they would remain in effect, see~\ref{sec:scope}.

Symbols are the simplest thing to detect, as the code in~\ref{lst:arith-symbol-lex} shows, they only require one character of lookahead.

\subsection{Parser}
The parser was not completed along with the lexer in the first iteration as had been planned.
It was finished in the second one along with extensions to Scope.

The tokens passed from the lexer are assigned to their node type by a simple switch statement.
The node types are used to abstract the functionality of similar operations.
For example $a + b$, $a * b$ and $a \mathrel{+}= b$, $a \mathrel{*}= b$ show that behaviour is similar and it is just the operation that differs in most cases .
Respectively they would be created as InfixNode and InfixAssignNode with their Types set to indicate what operation is desired.

The Pratt parser requires that each node have two functions and one value, see~\ref{lst:arith-node-interface}.
Since Go interfaces can only consist of methods I just changed the value to a getter method instead.

\subsection{Variables}
To begin with I created stub methods on the parser that would eventually interact with the supplied scope.

Values are converted to strings before being stored.
When they are retrieved if they can be parsed as any of octal, decimal or hex they are converted before being returned.
Variables that cannot be parsed are returned with a value of zero.

Variables can only be accessed by using their unprefixed form, i.e \verb!(( a = 5 ))! will work but \verb!(( $a = 5 ))! will not.
This is because variable expansion is done separately and before arithmetic expansion.
Time constraints and a flawed lexer design means that this does not currently work(See~\ref{sec:main-lexer-arith}.

\subsection{Ternary}
The ternary operator is unique in that it operates on three values.
Unfortunately due to the fact that the tree is constructed and then evaluated immediately this led to a bug.

When both sides of the environment contained assignment operators variables could be modified twice or always assigned the second value, E.g given \verb!y = 0! an equation like \\ \verb!x ? y += 1 : y += 3! would make \verb!y == 4! no matter what x was.

I left the bug with a failing test case but went back to fix it in the last iteration using the knowledge I had gained during the project.

\section{Scope}
\label{sec:scope}
The scope object was created during the second iteration alongside the arith parser.
It was also created as a subpackage because putting it in the main package was impossible since Go completely disallows circular references.

As is obvious from the package name, 'variables.Scope' and the headings in this section, the responsibilities of the class grew quickly and it quickly became mislabeled.
I realised the problems that had been created by the package layout
as I started to implement user functions in the penultimate iteration.
At this point it would have taken significant work to correct and the benefits would have been minimal.

\subsection{Variables}
The original Scope object was only used to get and set variables but it has lots of complexity.
It contains a list of hash tables which are searched in reverse order when setting, updating or retrieving anything.
The first value matching the name is used.

I created it this way as I knew that it would be needed by both commands with temporary assignments and functions using the local builtin.

Commands take a list of environment variables each as a string in the form, "VARNAME=FOO".
This meant that when I got to the stage when commands where being executed I had to add an Environ function to get them in the correct form.
The complexity of this function is O(2n), where n is the number of variables set in the shell, but I could not see a way to improve this without harming the performance of other aspects.

The design does not currently support integer typed variables but It could be added with minimal effort.
Change the Variable struct to contain an isInteger bool and when updating this variable using the result of arith.Parse as the new value. 
\subsection{User Functions}
User functions where added in the penultimate iteration.
The way they are stored in the Scope object shows how I was bitten by lack of forethought area of package layout.

\begin{verbatim}
type Scope struct {
	...
	Functions    map[string]interface{}
	...
}
\end{verbatim}

It shows that I have had to use a map of interface\{\} to store the NodeFunctions.
It is similar to a \verb!void *! in C as Go's implicit satisfaction of interfaces mean that everything satisfies the empty one.

This was done as storage and usage of a NodeFunction is done during the Eval phase which is defined in package main.
The solution would have been to create a subpackage for nodes.
However the work required to change the parser during the last week was greater than the bad practice of using interface\{\} here.

\subsection{Aliases}
Aliases where not done in the time frame.
They will however require storage in the Scope object and creation of a builtin command to put them there.

The way the main parser and lexer is created will also have to be different as the lexer expands aliases when they occur so needs knowledge of them.

They also only take effect after after the compound block they are declared in.
\begin{verbatim}
foofunc() {
	alias foo=echo
    foo "IT WORKS"
}

foofunc
\end{verbatim}
This would cause the shell to print an error as the alias is not yet visible as the function was parsed without it existing.


\section{Main Lexer}

\subsection{Strings}
\subsection{Variables}
\subsection{Subshells}
\subsection{Arithmetic}
\label{sec:main-lexer-arith}

\section{Main Parser, AST \& Nodes}

\subsection{Simple Command}
\subsection{Command}
\subsection{Pipeline}
\subsection{And Or}
\subsection{List}

\section{Expansion}

\subsection{Tilde}
\subsection{Substitutions}
\subsection{Globbing}
\subsection{Word Splitting}

\section{Builtin Commands}

\section{Circular References}
\label{sec:circular-refs}





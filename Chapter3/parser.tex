\section{Main Parser, AST \& Nodes}
The parser turns the tokens into nodes and constructs AST's with them.
It was developed iteratively as nodes and elements of the lexer where completed. 

Almost every node has a default exit status of success.
This is helpful as statements that dont run because their conditions evaluated false are showing correct behaviour.

Nodes also contain a number of other nodes depending on what they represent.
Terminal nodes such as NodeCommand, NodeEOF and NodeNoop are what other commands reduce too and don't contain further nodes.

The use of a node interface allows the behaviour of every node to be separated.
This is contrary to the design of dash which uses global state and a single function to dispatch to other evaluation functions.
This can be extremely confusing as it contains 7 GOTO statements and 6 blocks of conditional defines in only 128 lines (See~\ref{lst:dash-evaltree}).
While the single clear purpose of all the current Nodes means that changing behaviour in the future will be easy.


\subsection{Simple Command}
A simple command is a line that contains a command with optional arguments and variable assignments.
The command can be a builtin (See~\ref{sec:builtins}), a function (See~\ref{sec:user-functions}) or an external command.
Simple commands are stored as NodeCommand's which incorporate the logic of decided what type of command to run as well as expanding the arguments and any variable assignments.
If the line with assignments also has an external command call, the assignments are temporary and are removed when the command completes.

During the third iteration this was created to support commands with arguments.
It was expanded during the fourth to accommodate variables assignments and during the fifth, for arguments that contained substitutions.
The simple command function is also the place that function definitions are detected and this was added during the penultimate iteration.

\subsection{Command}
Command is the function that parses the command structures of the code.
This includes the 'if', 'for', 'until', 'while' and 'case' expressions.
The code for parsing these is separated from the main function as they can be quite long.
One of the longest functions in the codebase is the parsing routine for a case statement and by splitting these up it allows you to focus on one thing at a time.

Each type of command has its own node that handles the details of its execution.
The NodeFor, NodeWhile and NodeUntil will have to understand the break and continue commands once they have been implemented.

Along with the commands that people expect this is also the place that command grouping occurs.
This feature is often seen when defining shell functions and some people may believe that, like in other languages, it is a part of their definition syntax.
However it can be used anywhere a command can including in a pipeline or in a conditional to avoid certain bugs.
A command group begins with a '\{' and ends with a corresponding '\}'.
Anything contained between the two is parsed as a separate group which allows redirections to be applied to everything it contains.
See the code in~\ref{lst:command-grouping} for examples.

\subsection{Pipeline}
The pipeline is a list of commands that will join their inputs and outputs to each other and then be run in parallel.

This allows simple utilities to be combined to produce complex transformations.
Since they are conducted in memory buffers overhead can be reduced by such an amount that they can be faster than common distributed computing tools like Hadoop\cite{AdamD45:online}.
Pipelines also encourage the Unix philosophies of programs that 'Do one thing and do it well' and 'Handle text streams; the universal interface'.
Observing this can help users solve problems with almost no programming\cite{LITERATE-VS-SHELL}.

The Pipeline node reuses the NodeList to store the commands to be executed.
This means that the only thing that the only thing it has to do is create piped IO channels for each commands input and output and launch them in separate go-routines.
This is a naive approach as it does not take into account the exit codes of these commands.
This will be required for the 'set -e' option which exits the shell on any error.
It will also have to be changed when job control is added as the ability to suspend and resume commands takes some complex bookkeeping.

The pipeline function also handles negation of the exit code.
Any Command or pipe prefixed with a '!' returns the opposite of its exit code, for 0 the return becomes 1, for any other value it becomes 0.

The NodeNegate is very simple just encoding this logic after running the AST it contains.

\subsection{And Or}
The AndOr function takes the nodes produced by pipeline and joins them together.

The NodeBinary is used to do this and since everything is built on the node interface the can accept another NodeBinary as one of its arguments allowing easy conditional chaining.

The Node has the logic for both 'or' and 'and' since they work the similarly, just comparing to a different return value from the left side of the conditional.


\subsection{List}

The list   XXX











